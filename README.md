# Generative-AI

# Generative AI Introduction
## 1.What is Generative AI?
##### Generative AI generates new data based on training sample.     
##### Generative model can generate Image, Text, Audi, Vedio etc. data as output.    
##### ChatGPT/Google Gemini/Meta Llama    

## 2.Why are generative models required?
##### Understand Complex Pattern from Data
##### Content generation
##### Build Powerful Application, such as ChatGPT/Google Gemini/Meta Llama

## 3.Where Generative AI Exists
##### Machine Learning is the subset of Artificial Intelligence
##### Deep Learning is the subset of Machine Learning
##### Generative AI is the subset of Deep Learning

## 4.Discriminative Model vs Generative Model
##### Discriminative model is nothing but just a predictive model.
##### Generative Model can take any kinds of noise data and from that kind of noise data, it will generate a complete new data for you.

## 5.Generative Ai is a subset of deep learning and Generative models are trained on huge amount of data. While training the generative model we don't need to provide a label data, It is not possible when we have a huge amount of data, So, it's just try to see the relationship between the distribution of the data. In Generative AI we give unstructured data to the LLM model for training purpose.

## 6.What is LLMs?
##### Large Language Models are foundational machine learning models that use deep learning algorithms to process and understand natural language. These models are trained on massive amounts of text data to learn patterns and entity relationships in the language.
##### It is a language model which is responsible for performing tasks such as text to text generation, text to image generation and image to text generations.
##### LLM is our generative model.So, LLM is subset of deep learning. 

# Generative AI End to End pipeline
## 1.End to end Generative AI pipeline
##### Generative AI pipeline is a set of steps followed to build an end to end GenAI software.

## 2.Generative AI pipeline
##### Data acquisition - Data Processing - Feature engineering - Modeling - Evaluation - Deployment - Monitoring and model updating

###### Step1. Data acquisition
###### check available data (csv, txt, pdf, docs,xlsx)
###### other data (DB, Internet, API)
###### no data, then creating your own data: LLM, if you have less data, then you can perform Data Augmentation: replace with synonyms, biagram flip, back translation, add additional noise

##### Step2: Data Processing
###### cleanup: html tags, emoji, spelling correction,etc 
###### basic preprocessing: tokenization (word level and sentence level)
###### optional preprocessing: stop word removal; streaming; lemmatization; punctuation removal; lower case; language detection
###### advance preprocessing: parts of speech tagging; parsing; coreference resolution

##### Step3: Feature Engineering
###### text vectorization

##### Step4: Modeling
###### paid model and open source model

##### Step5: Evaluation
###### Intrinsic and Extrinsic evaluation

##### Step6: Deployment & Monitoring  & Re-training the model

## Common Term
##### conpus: entire text
##### vocabulary: unique word
##### documents: one line
##### word: single word
